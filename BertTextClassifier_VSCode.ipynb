{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertTextClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loretoparisi/bert_text_classifier/blob/master/BertTextClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.7/site-packages (2.2.1)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.7/site-packages (from transformers) (0.1.82)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (from transformers) (1.9.156)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from transformers) (2.22.0)\nRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/site-packages (from transformers) (0.0.35)\nRequirement already satisfied: regex in /usr/local/lib/python3.7/site-packages (from transformers) (2019.11.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from transformers) (4.28.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from transformers) (1.15.4)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\nRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.7/site-packages (from boto3->transformers) (0.2.0)\nRequirement already satisfied: botocore<1.13.0,>=1.12.156 in /usr/local/lib/python3.7/site-packages (from boto3->transformers) (1.12.156)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->transformers) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->transformers) (2019.3.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->transformers) (1.25.3)\nRequirement already satisfied: joblib in /usr/local/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\nRequirement already satisfied: click in /usr/local/lib/python3.7/site-packages (from sacremoses->transformers) (6.7)\nRequirement already satisfied: six in /usr/local/Cellar/ipython/7.1.1/libexec/vendor/lib/python3.7/site-packages (from sacremoses->transformers) (1.11.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/Cellar/ipython/7.1.1/libexec/vendor/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.156->boto3->transformers) (2.7.5)\nRequirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.156->boto3->transformers) (0.14)\n\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: torch in /usr/local/lib/python3.7/site-packages (1.3.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch) (1.15.4)\n\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: fastai in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (1.0.59)\nRequirement already satisfied: numexpr in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from fastai) (2.7.0)\nRequirement already satisfied: bottleneck in /usr/local/lib/python3.7/site-packages (from fastai) (1.3.1)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/site-packages (from fastai) (1.3.1)\nRequirement already satisfied: Pillow in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from fastai) (6.2.1)\nRequirement already satisfied: nvidia-ml-py3 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from fastai) (7.352.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from fastai) (2.22.0)\nRequirement already satisfied: pynvx>=1.0.0; platform_system == \"Darwin\" in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from fastai) (1.0.0)\nRequirement already satisfied: packaging in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from fastai) (19.2)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/site-packages (from fastai) (4.8.0)\nRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/site-packages (from fastai) (1.15.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from fastai) (0.23.4)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (from fastai) (3.0.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (from fastai) (1.1.0)\nRequirement already satisfied: fastprogress>=0.1.19 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from fastai) (0.1.22)\nRequirement already satisfied: spacy>=2.0.18 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from fastai) (2.2.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from fastai) (5.1)\nRequirement already satisfied: torchvision in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from fastai) (0.4.2)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->fastai) (1.25.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->fastai) (2019.3.9)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->fastai) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->fastai) (2.8)\nRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->fastai) (2.2.2)\nRequirement already satisfied: six in /usr/local/Cellar/ipython/7.1.1/libexec/vendor/lib/python3.7/site-packages (from packaging->fastai) (1.11.0)\nRequirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.7/site-packages (from beautifulsoup4->fastai) (1.9.2)\nRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/Cellar/ipython/7.1.1/libexec/vendor/lib/python3.7/site-packages (from pandas->fastai) (2.7.5)\nRequirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/site-packages (from pandas->fastai) (2018.7)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib->fastai) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->fastai) (1.0.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (41.4.0)\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from spacy>=2.0.18->fastai) (0.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from spacy>=2.0.18->fastai) (3.0.2)\nRequirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from spacy>=2.0.18->fastai) (0.4.1)\nRequirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from spacy>=2.0.18->fastai) (7.3.1)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from spacy>=2.0.18->fastai) (2.0.3)\nRequirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from spacy>=2.0.18->fastai) (0.2.0)\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from spacy>=2.0.18->fastai) (1.1.3)\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from spacy>=2.0.18->fastai) (0.4.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from spacy>=2.0.18->fastai) (1.0.2)\nRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai) (1.2.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.0.18->fastai) (4.28.1)\nRequirement already satisfied: zipp>=0.5 in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai) (0.6.0)\nRequirement already satisfied: more-itertools in /Users/loretoparisi/Library/Python/3.7/lib/python/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai) (8.0.2)\n\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "I1206 16:05:11.071485 4472526272 file_utils.py:40] PyTorch version 1.3.1 available.\n"
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "fastai version : 1.0.59\ntransformers version : 2.2.1\n"
        }
      ],
      "source": [
        "import fastai\n",
        "import transformers\n",
        "print('fastai version :', fastai.__version__)\n",
        "print('transformers version :', transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASETS_URL = {\n",
        "    'wikitext-2':   {'train': \"https://s3.amazonaws.com/datasets.huggingface.co/wikitext-2/train.txt\",\n",
        "                     'valid': \"https://s3.amazonaws.com/datasets.huggingface.co/wikitext-2/valid.txt\"},\n",
        "    'wikitext-103': {'train': \"https://s3.amazonaws.com/datasets.huggingface.co/wikitext-103/wiki.train.tokens\",\n",
        "                     'valid': \"https://s3.amazonaws.com/datasets.huggingface.co/wikitext-103/wiki.valid.tokens\"},\n",
        "    'simplebooks-2-raw': {'train': \"https://s3.amazonaws.com/datasets.huggingface.co/simplebooks-2-raw/train.txt\",\n",
        "                          'valid': \"https://s3.amazonaws.com/datasets.huggingface.co/simplebooks-2-raw/valid.txt\"},\n",
        "    'simplebooks-92-raw': {'train': \"https://s3.amazonaws.com/datasets.huggingface.co/simplebooks-92-raw/train.txt\",\n",
        "                           'valid': \"https://s3.amazonaws.com/datasets.huggingface.co/simplebooks-92-raw/valid.txt\"},\n",
        "    'imdb': {'train': \"https://s3.amazonaws.com/datasets.huggingface.co/aclImdb/train.txt\",\n",
        "             'test': \"https://s3.amazonaws.com/datasets.huggingface.co/aclImdb/test.txt\"},\n",
        "    'trec': {'train': \"https://s3.amazonaws.com/datasets.huggingface.co/trec/train.txt\",\n",
        "             'test': \"https://s3.amazonaws.com/datasets.huggingface.co/trec/test.txt\"},\n",
        "    }\n",
        "\n",
        "DATASETS_LABELS_URL = {\n",
        "    'imdb': {'train': \"https://s3.amazonaws.com/datasets.huggingface.co/aclImdb/train.labels.txt\",\n",
        "             'test': \"https://s3.amazonaws.com/datasets.huggingface.co/aclImdb/test.labels.txt\"},\n",
        "    'trec': {'train': \"https://s3.amazonaws.com/datasets.huggingface.co/trec/train.labels.txt\",\n",
        "             'test': \"https://s3.amazonaws.com/datasets.huggingface.co/trec/test.labels.txt\"},\n",
        "    }\n",
        "\n",
        "DATASETS_LABELS_CONVERSION = {\n",
        "    'imdb':         {'pos': 0, 'neg': 1},\n",
        "    'trec':         {'NUM': 0, 'LOC': 1, 'HUM': 2, 'DESC': 3, 'ENTY': 4, 'ABBR': 5},\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "(156060, 4) (66292, 3)\n"
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Phrase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>156061</td>\n      <td>8545</td>\n      <td>An intermittently pleasing but mostly routine ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>156062</td>\n      <td>8545</td>\n      <td>An intermittently pleasing but mostly routine ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>156063</td>\n      <td>8545</td>\n      <td>An</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>156064</td>\n      <td>8545</td>\n      <td>intermittently pleasing but mostly routine effort</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>156065</td>\n      <td>8545</td>\n      <td>intermittently pleasing but mostly routine</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   PhraseId  SentenceId                                             Phrase\n0    156061        8545  An intermittently pleasing but mostly routine ...\n1    156062        8545  An intermittently pleasing but mostly routine ...\n2    156063        8545                                                 An\n3    156064        8545  intermittently pleasing but mostly routine effort\n4    156065        8545         intermittently pleasing but mostly routine"
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/loretoparisi/bert_text_classifier/master/data/imdb_kaggle/train.tsv', sep=\"\\t\", quoting=csv.QUOTE_ALL, engine=\"python\", quotechar='\"', encoding=\"utf-8\")\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/loretoparisi/bert_text_classifier/master/data/imdb_kaggle/test.tsv', sep=\"\\t\", quoting=csv.QUOTE_ALL, engine=\"python\", quotechar='\"', encoding=\"utf-8\")\n",
        "\n",
        "print(train.shape, test.shape)\n",
        "train.head()\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters\n",
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n",
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-base' # 'roberta-base-openai-detector'\n",
        "\n",
        "# model_type = 'bert'\n",
        "# pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "# model_type = 'distilbert'\n",
        "# pretrained_model_name = 'distilbert-base-uncased-distilled-squad'#'distilbert-base-uncased'#'distilbert-base-uncased'\n",
        "\n",
        "#model_type = 'xlm'\n",
        "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "#model_type = 'xlnet'\n",
        "#pretrained_model_name = 'xlnet-base-cased'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_class.pretrained_model_archive_map.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seed_all(seed_value):\n",
        "    ''' Function to set the seed for generating random numbers. '''\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Cu8f2UPgLfGD"
      },
      "outputs": [],
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "        return [CLS] + tokens + [SEP]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "b8FVnLsvLjvk"
      },
      "outputs": [],
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7BemsGxvLzwe"
      },
      "outputs": [],
      "source": [
        "tokenizer_class.pretrained_vocab_files_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DnROdf3AMFvg"
      },
      "outputs": [],
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "onUvhVSjMKp_"
      },
      "outputs": [],
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WQnxo0eNMWJC"
      },
      "outputs": [],
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zjx_eCYzMbEQ"
      },
      "outputs": [],
      "source": [
        "databunch = (TextList.from_df(train, cols='Phrase', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'Sentiment')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qOagk4oKHVTy"
      },
      "outputs": [],
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "databunch.show_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "P798q34BHcA_"
      },
      "outputs": [],
      "source": [
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n",
        "test_one_batch = databunch.one_batch()[0]\n",
        "print('Batch shape : ',test_one_batch.shape)\n",
        "print(test_one_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-SMDRFClHfxH"
      },
      "outputs": [],
      "source": [
        "# defining our model architecture \n",
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BfLfKcxAHiYs"
      },
      "outputs": [],
      "source": [
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = 5\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Zf5n9Y6zHnOR"
      },
      "outputs": [],
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "woqc7pDPH0i6"
      },
      "outputs": [],
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = lambda input: AdamW(input,correct_bias=False), \n",
        "                  metrics=[accuracy])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Seems to not working\n",
        "if use_fp16: learner = learner.to_fp16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YpN9Hz7kH30f"
      },
      "outputs": [],
      "source": [
        "print(learner.model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bvxG4YSjIAs7"
      },
      "outputs": [],
      "source": [
        "# For DistilBERT\n",
        "# list_layers = [learner.model.transformer.distilbert.embeddings,\n",
        "#                learner.model.transformer.distilbert.transformer.layer[0],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[1],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[2],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[3],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[4],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[5],\n",
        "#                learner.model.transformer.pre_classifier]\n",
        "\n",
        "# For roberta-base\n",
        "list_layers = [learner.model.transformer.roberta.embeddings,\n",
        "              learner.model.transformer.roberta.encoder.layer[0],\n",
        "              learner.model.transformer.roberta.encoder.layer[1],\n",
        "              learner.model.transformer.roberta.encoder.layer[2],\n",
        "              learner.model.transformer.roberta.encoder.layer[3],\n",
        "              learner.model.transformer.roberta.encoder.layer[4],\n",
        "              learner.model.transformer.roberta.encoder.layer[5],\n",
        "              learner.model.transformer.roberta.encoder.layer[6],\n",
        "              learner.model.transformer.roberta.encoder.layer[7],\n",
        "              learner.model.transformer.roberta.encoder.layer[8],\n",
        "              learner.model.transformer.roberta.encoder.layer[9],\n",
        "              learner.model.transformer.roberta.encoder.layer[10],\n",
        "              learner.model.transformer.roberta.encoder.layer[11],\n",
        "              learner.model.transformer.roberta.pooler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ONipJ8kzINy9"
      },
      "outputs": [],
      "source": [
        "learner.split(list_layers)\n",
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')\n",
        "print(learner.layer_groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "77bEbzQVIUmD"
      },
      "outputs": [],
      "source": [
        "learner.save('untrain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "D7jZOCkDIX1v"
      },
      "outputs": [],
      "source": [
        "seed_all(seed)\n",
        "learner.load('untrain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OltDLZjIIad4"
      },
      "outputs": [],
      "source": [
        "learner.freeze_to(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lhUKJKtBIdih"
      },
      "outputs": [],
      "source": [
        "learner.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "10zfzvafIsLU"
      },
      "outputs": [],
      "source": [
        "learner.lr_find()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "A697rmz2MezZ"
      },
      "outputs": [],
      "source": [
        "learner.recorder.plot(skip_end=7,suggestion=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GV5IZhJcMjLR"
      },
      "outputs": [],
      "source": [
        "learner.fit_one_cycle(1,max_lr=2e-03,moms=(0.8,0.7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fHqAxqjmYV9F"
      },
      "outputs": [],
      "source": [
        "learner.save('first_cycle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qcKthjX-YbSO"
      },
      "outputs": [],
      "source": [
        "seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "480OI-4TYdeG"
      },
      "outputs": [],
      "source": [
        "learner.load('first_cycle');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AMXmnXOnYiHo"
      },
      "outputs": [],
      "source": [
        "learner.freeze_to(-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "D3yEC0ewYlFF"
      },
      "outputs": [],
      "source": [
        "lr = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Xhv6mMy8YoL-"
      },
      "outputs": [],
      "source": [
        "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3KDWAhY4ae1F"
      },
      "outputs": [],
      "source": [
        "learner.save('second_cycle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "H8Rpt6K3ahZY"
      },
      "outputs": [],
      "source": [
        "seed_all(seed)\n",
        "learner.load('second_cycle');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iYmfhNQ1alSP"
      },
      "outputs": [],
      "source": [
        "learner.freeze_to(-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F_Lca2f9apep"
      },
      "outputs": [],
      "source": [
        "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GNFnkd2gcZls"
      },
      "outputs": [],
      "source": [
        "learner.save('third_cycle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ViGNwHOFcblt"
      },
      "outputs": [],
      "source": [
        "seed_all(seed)\n",
        "learner.load('third_cycle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TrqF3p2CceVz"
      },
      "outputs": [],
      "source": [
        "learner.unfreeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dCNKO43HcgrJ"
      },
      "outputs": [],
      "source": [
        "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wmc3viqUnElD"
      },
      "outputs": [],
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    the get_preds method does not yield the elements in order by default\n",
        "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
        "    \"\"\"\n",
        "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    return preds[reverse_sampler, :]\n",
        "\n",
        "test_preds = get_preds_as_nparray(DatasetType.Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0WktiIvznyXO"
      },
      "outputs": [],
      "source": [
        "sample_submission = pd.read_csv('https://raw.githubusercontent.com/loretoparisi/bert_text_classifier/master/data/imdb_kaggle/sampleSubmission.csv', quoting=csv.QUOTE_ALL, engine=\"python\", quotechar='\"', encoding=\"utf-8\")\n",
        "print(sample_submission.shape)\n",
        "sample_submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ytrKMCKmoq49"
      },
      "outputs": [],
      "source": [
        "sample_submission['Sentiment'] = np.argmax(test_preds,axis=1)\n",
        "sample_submission.to_csv(\"predictions.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BtKSbVzRou8b"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FFSixD0Box6z"
      },
      "outputs": [],
      "source": [
        "sample_submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KE3QoukZo2ME"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n",
        "    html = '<a href={filename}>{title}</a>'\n",
        "    html = html.format(title=title,filename=filename)\n",
        "    return HTML(html)\n",
        "\n",
        "# create a link to download the dataframe which was saved with .to_csv method\n",
        "create_download_link(filename='predictions.csv')"
      ]
    }
  ]
}